#!/usr/bin/env python3
"""
Test script for fine-tuned Kazakh Law Gemma model
"""

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import os

def load_model(model_path="./gemma_kazakh_law_finetuned"):
    """Load the fine-tuned model"""
    print("Loading model...")
    
    # Determine base model from config
    base_model_name = "google/gemma-3-1b-it"  # Change if you used different base model
    
    # Load base model
    base_model = AutoModelForCausalLM.from_pretrained(
        base_model_name,
        torch_dtype=torch.float16,
        device_map="auto",
        low_cpu_mem_usage=True
    )
    
    # Load LoRA adapter
    model = PeftModel.from_pretrained(base_model, model_path)
    
    # Load tokenizer
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    
    print("Model loaded successfully!")
    return model, tokenizer

def generate_answer(model, tokenizer, question, max_tokens=300):
    """Generate answer for a given question"""
    
    # Format prompt
    prompt = f"<bos><start_of_turn>user\n{question}<end_of_turn>\n<start_of_turn>model\n"
    
    # Tokenize
    inputs = tokenizer(prompt, return_tensors="pt")
    
    # Move to device if using MPS
    device = next(model.parameters()).device
    inputs = {k: v.to(device) for k, v in inputs.items()}
    
    # Generate
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_tokens,
            temperature=0.7,
            do_sample=True,
            top_p=0.9,
            pad_token_id=tokenizer.eos_token_id,
            eos_token_id=tokenizer.convert_tokens_to_ids("<end_of_turn>")
        )
    
    # Decode and extract answer
    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    answer = full_response.split("<start_of_turn>model\n")[-1].strip()
    
    return answer

def main():
    """Interactive testing"""
    
    if not os.path.exists("./gemma_kazakh_law_finetuned"):
        print("Error: Fine-tuned model not found!")
        print("Make sure you've run fine_tune_gemma_local.py first")
        return
    
    try:
        model, tokenizer = load_model()
        model.eval()  # Set to evaluation mode
        
        print("\n" + "="*60)
        print("üèõÔ∏è  –ö–ê–ó–ê–•–°–ö–ò–ô –ü–†–ê–í–û–í–û–ô –ê–°–°–ò–°–¢–ï–ù–¢ –ù–ê –û–°–ù–û–í–ï GEMMA")
        print("="*60)
        print("–ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –∫–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–æ–º—É –ø—Ä–∞–≤—É!")
        print("–ù–∞–ø–∏—à–∏—Ç–µ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞\n")
        
        # Test questions
        test_questions = [
            "–ö–∞–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –¢–û–û –≤ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–µ?",
            "–ö–∞–∫–æ–≤–∞ –ø—Ä–æ—Ü–µ–¥—É—Ä–∞ —Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏—è —Ç—Ä—É–¥–æ–≤–æ–≥–æ –¥–æ–≥–æ–≤–æ—Ä–∞ –≤ –†–ö?",
            "–ö–∞–∫–∏–µ –Ω–∞–ª–æ–≥–∏ –æ–±—è–∑–∞–Ω–æ –ø–ª–∞—Ç–∏—Ç—å –¢–û–û –≤ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–µ?",
            "–ö–∞–∫–æ–≤–∞ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–µ –Ω–∞–ª–æ–≥–æ–≤–æ–≥–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞?",
        ]
        
        print("–ü—Ä–∏–º–µ—Ä—ã –≤–æ–ø—Ä–æ—Å–æ–≤:")
        for i, q in enumerate(test_questions, 1):
            print(f"{i}. {q}")
        print()
        
        while True:
            question = input("üí¨ –í–∞—à –≤–æ–ø—Ä–æ—Å: ").strip()
            
            if question.lower() in ['exit', '–≤—ã—Ö–æ–¥', 'quit']:
                break
                
            if not question:
                continue
                
            print("\nü§î –î—É–º–∞—é...")
            
            try:
                answer = generate_answer(model, tokenizer, question)
                print(f"\nüìú –û—Ç–≤–µ—Ç:\n{answer}\n")
                print("-" * 60)
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
        
        print("–î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
        print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å —É—Å–ø–µ—à–Ω–æ")

if __name__ == "__main__":
    main() 