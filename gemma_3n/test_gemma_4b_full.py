#!/usr/bin/env python3
"""
Interactive testing for fully trained Gemma 3 4B model
"""

import os
import sys
from mlx_lm import load, generate

def get_latest_checkpoint():
    """Get the latest checkpoint"""
    if not os.path.exists('checkpoints_full'):
        return None
    
    # MLX saves final adapters directly
    if os.path.exists('checkpoints_full/adapters.safetensors'):
        return 'checkpoints_full'
    
    # Look for numbered checkpoints
    files = os.listdir('checkpoints_full')
    checkpoint_files = [f for f in files if f.endswith('_adapters.safetensors')]
    if not checkpoint_files:
        return None
    
    # Get latest by number
    latest_file = max(checkpoint_files, key=lambda x: int(x.split('_')[0]))
    iteration = latest_file.split('_')[0]
    return f"checkpoints_full"  # MLX loads from directory, not specific file

def interactive_chat():
    """Interactive chat with trained model"""
    print("üèõÔ∏è **GEMMA 3 4B - –ü–û–õ–ù–ê–Ø –ú–û–î–ï–õ–¨ –ö–ê–ó–ê–•–°–¢–ê–ù–°–ö–û–ì–û –ü–†–ê–í–ê**")
    print("=" * 60)
    
    try:
        checkpoint_path = get_latest_checkpoint()
        if not checkpoint_path:
            print("‚ùå –ß–µ–∫–ø–æ–∏–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            return
        
        print(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å —á–µ–∫–ø–æ–∏–Ω—Ç–æ–º: {checkpoint_path}")
        
        model, tokenizer = load(
            "google/gemma-3-4b-it",
            adapter_path=checkpoint_path
        )
        
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        print("\nüí¨ –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –∫–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–æ–º—É –ø—Ä–∞–≤—É")
        print("   (–¥–ª—è –≤—ã—Ö–æ–¥–∞ –Ω–∞–ø–∏—à–∏—Ç–µ 'exit')")
        print("-" * 60)
        
        while True:
            question = input("\nüìù –í–∞—à –≤–æ–ø—Ä–æ—Å: ").strip()
            
            if question.lower() in ['exit', '–≤—ã—Ö–æ–¥', 'quit']:
                print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                break
            
            if not question:
                continue
            
            print("ü§î –î—É–º–∞—é...")
            
            prompt = f"<bos><start_of_turn>user\n{question}<end_of_turn>\n<start_of_turn>model\n"
            
            try:
                response = generate(
                    model, 
                    tokenizer, 
                    prompt=prompt, 
                    max_tokens=400
                )
                
                print(f"\nü§ñ –û—Ç–≤–µ—Ç: {response}\n")
                print("-" * 60)
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
                
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")

def benchmark_test():
    """Quick benchmark test"""
    print("‚ö° **–ë–ï–ù–ß–ú–ê–†–ö –¢–ï–°–¢**")
    
    checkpoint_path = get_latest_checkpoint()
    if not checkpoint_path:
        print("‚ùå –ß–µ–∫–ø–æ–∏–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return
    
    try:
        import time
        from mlx_lm import load, generate
        
        print("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
        start_time = time.time()
        
        model, tokenizer = load(
            "google/gemma-3-4b-it",
            adapter_path=checkpoint_path
        )
        
        load_time = time.time() - start_time
        print(f"‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞: {load_time:.2f} —Å–µ–∫")
        
        # Benchmark generation
        prompt = "<bos><start_of_turn>user\n–ß—Ç–æ —Ç–∞–∫–æ–µ –¢–û–û –≤ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–µ?<end_of_turn>\n<start_of_turn>model\n"
        
        start_time = time.time()
        response = generate(model, tokenizer, prompt=prompt, max_tokens=100)
        gen_time = time.time() - start_time
        
        tokens = len(response.split())
        speed = tokens / gen_time if gen_time > 0 else 0
        
        print(f"üöÄ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è: {gen_time:.2f} —Å–µ–∫")
        print(f"üìä –°–∫–æ—Ä–æ—Å—Ç—å: {speed:.1f} —Ç–æ–∫–µ–Ω–æ–≤/—Å–µ–∫")
        print(f"üìù –û—Ç–≤–µ—Ç: {response}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

def main():
    if len(sys.argv) > 1:
        if sys.argv[1] == "benchmark":
            benchmark_test()
        else:
            print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python test_gemma_4b_full.py [benchmark]")
    else:
        interactive_chat()

if __name__ == "__main__":
    main() 