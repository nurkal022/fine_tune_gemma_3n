#!/usr/bin/env python3
"""
Fix dataset formatting for MLX training
"""

import os
import json
from sklearn.model_selection import train_test_split

def fix_dataset():
    """Fix and recreate properly formatted dataset"""
    print("üîß –ò—Å–ø—Ä–∞–≤–ª—è—é —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    
    # Load original data
    dataset_path = "final_training_dataset/kazakh_law_qa_full_20250702_013138.jsonl"
    
    with open(dataset_path, 'r', encoding='utf-8') as f:
        raw_data = [json.loads(line) for line in f]
    
    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(raw_data)} –∑–∞–ø–∏—Å–µ–π")
    
    # Create data directory
    os.makedirs("data", exist_ok=True)
    
    # Format for MLX training with proper escaping
    mlx_data = []
    for item in raw_data:
        # Clean text and ensure proper formatting
        instruction = item['instruction'].replace('\n', ' ').replace('\r', ' ')
        output = item['output'].replace('\n', ' ').replace('\r', ' ')
        
        # Create proper MLX format
        formatted_text = f"<bos><start_of_turn>user\n{instruction}<end_of_turn>\n<start_of_turn>model\n{output}<end_of_turn><eos>"
        
        mlx_data.append({"text": formatted_text})
    
    # Split data
    train_data, valid_data = train_test_split(mlx_data, test_size=0.1, random_state=42)
    
    print(f"‚úÖ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ: {len(train_data)} –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, {len(valid_data)} –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
    
    # Save with proper JSON formatting
    with open("data/train.jsonl", 'w', encoding='utf-8') as f:
        for item in train_data:
            json.dump(item, f, ensure_ascii=False, separators=(',', ':'))
            f.write('\n')
    
    with open("data/valid.jsonl", 'w', encoding='utf-8') as f:
        for item in valid_data:
            json.dump(item, f, ensure_ascii=False, separators=(',', ':'))
            f.write('\n')
    
    print("‚úÖ –î–∞—Ç–∞—Å–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω!")
    return True

if __name__ == "__main__":
    fix_dataset() 