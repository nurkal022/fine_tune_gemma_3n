# üîß –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º Gemma 3 4B

## üö® –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è

### 1. –û—à–∏–±–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏

#### –ü—Ä–æ–±–ª–µ–º–∞: "No module named 'mlx_lm'"
```bash
ImportError: No module named 'mlx_lm'
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
source ../gemma_env/bin/activate

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É
pip list | grep mlx

# –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
pip install mlx-lm
```

#### –ü—Ä–æ–±–ª–µ–º–∞: "Checkpoint not found"
```bash
FileNotFoundError: [Errno 2] No such file or directory: './checkpoints_full'
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
ls -la checkpoints_full/

# –î–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ñ–∞–π–ª—ã:
# adapters.safetensors
# adapter_config.json
# 0001000_adapters.safetensors

# –ï—Å–ª–∏ –Ω–µ—Ç - –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–Ω–æ–≤–æ
python full_training.py
```

#### –ü—Ä–æ–±–ª–µ–º–∞: "Model loading timeout"
```bash
TimeoutError: Model loading took too long
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –û—á–∏—Å—Ç–∏—Ç–µ –∫—ç—à HuggingFace
rm -rf ~/.cache/huggingface/

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º —Ç–∞–π–º–∞—É—Ç–æ–º
export HF_HUB_DISABLE_PROGRESS_BARS=1
python test_gemma_4b_full.py
```

### 2. –ü—Ä–æ–±–ª–µ–º—ã —Å –ø–∞–º—è—Ç—å—é

#### –ü—Ä–æ–±–ª–µ–º–∞: "Out of Memory (OOM)"
```bash
RuntimeError: [MPS] out of memory
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω—É—é –ø–∞–º—è—Ç—å
python -c "import psutil; print(f'RAM: {psutil.virtual_memory().available/1024**3:.1f}GB')"

# –ï—Å–ª–∏ –º–µ–Ω—å—à–µ 12GB - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å
cd ../  # –í–µ—Ä–Ω–∏—Ç–µ—Å—å –∫ Gemma 1B
python test_gemma_1b.py

# –ò–ª–∏ —É–º–µ–Ω—å—à–∏—Ç–µ max_tokens
python test_gemma_4b_full.py benchmark --max_tokens 100
```

#### –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
```bash
# –°–∫–æ—Ä–æ—Å—Ç—å –Ω–∏–∂–µ 5 —Ç–æ–∫–µ–Ω–æ–≤/—Å–µ–∫
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
import psutil

# CPU
print(f"CPU: {psutil.cpu_percent()}%")

# –ü–∞–º—è—Ç—å
mem = psutil.virtual_memory()
print(f"RAM: {mem.percent}% ({mem.used/1024**3:.1f}/{mem.total/1024**3:.1f}GB)")

# –ó–∞–∫—Ä–æ–π—Ç–µ –¥—Ä—É–≥–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
# –£–º–µ–Ω—å—à–∏—Ç–µ max_tokens
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ temperature=0.1 (–±—ã—Å—Ç—Ä–µ–µ)
```

### 3. –ü—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤

#### –ü—Ä–æ–±–ª–µ–º–∞: –ü–æ–≤—Ç–æ—Ä—è—é—â–∏–π—Å—è —Ç–µ–∫—Å—Ç
```
–û—Ç–≤–µ—Ç: "–¢–û–û —ç—Ç–æ –¢–û–û —ç—Ç–æ –¢–û–û —ç—Ç–æ..."
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
# –£–≤–µ–ª–∏—á—å—Ç–µ repetition_penalty
response = generate(
    model, tokenizer,
    prompt=prompt,
    repetition_penalty=1.1,  # –ò–ª–∏ 1.2
    temp=0.1
)
```

#### –ü—Ä–æ–±–ª–µ–º–∞: –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–≤–µ—Ç—ã
```
–û—Ç–≤–µ—Ç: "–¢–û–û - —ç—Ç–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è."
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
# –£–≤–µ–ª–∏—á—å—Ç–µ max_tokens –∏ —É–ª—É—á—à–∏—Ç–µ –ø—Ä–æ–º–ø—Ç
prompt = f"""<bos><start_of_turn>user
–ü–æ–¥—Ä–æ–±–Ω–æ –æ–±—ä—è—Å–Ω–∏: {question}

–¢—Ä–µ–±—É–µ—Ç—Å—è:
- –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
- –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã
- –°—Å—ã–ª–∫–∏ –Ω–∞ –∑–∞–∫–æ–Ω—ã<end_of_turn>
<start_of_turn>model
"""

response = generate(
    model, tokenizer,
    prompt=prompt,
    max_tokens=400,  # –ë–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤
    temp=0.1
)
```

#### –ü—Ä–æ–±–ª–µ–º–∞: –ù–µ—Ç–æ—á–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
```
–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–µ –ø–æ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—É
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
# –£–∫–∞–∂–∏—Ç–µ —é—Ä–∏—Å–¥–∏–∫—Ü–∏—é –≤ –ø—Ä–æ–º–ø—Ç–µ
prompt = f"""<bos><start_of_turn>user
–°–æ–≥–ª–∞—Å–Ω–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤—É –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω: {question}<end_of_turn>
<start_of_turn>model
"""

# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ—á–µ–Ω—å –Ω–∏–∑–∫—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É
response = generate(
    model, tokenizer,
    prompt=prompt,
    temp=0.05,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
    max_tokens=300
)
```

### 4. –ü—Ä–æ–±–ª–µ–º—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

#### –ü—Ä–æ–±–ª–µ–º–∞: –î–æ–ª–≥–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
```bash
# –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–Ω–∏–º–∞–µ—Ç –±–æ–ª—å—à–µ 10 —Å–µ–∫—É–Ω–¥
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
# –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å –æ–¥–∏–Ω —Ä–∞–∑
class ModelManager:
    def __init__(self):
        self.model = None
        self.tokenizer = None
        
    def load_once(self):
        if self.model is None:
            print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
            self.model, self.tokenizer = load(
                "google/gemma-3-4b-it",
                adapter_path="./checkpoints_full"
            )
        return self.model, self.tokenizer

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä
manager = ModelManager()
model, tokenizer = manager.load_once()
```

#### –ü—Ä–æ–±–ª–µ–º–∞: –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU
```bash
# CPU –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–∞ 100%
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –û–≥—Ä–∞–Ω–∏—á—å—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤
export MKL_NUM_THREADS=4
export OMP_NUM_THREADS=4

# –ò–ª–∏ –≤ Python
import os
os.environ['MKL_NUM_THREADS'] = '4'
os.environ['OMP_NUM_THREADS'] = '4'

# –ó–∞–∫—Ä–æ–π—Ç–µ –±—Ä–∞—É–∑–µ—Ä –∏ –¥—Ä—É–≥–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
```

### 5. –ü—Ä–æ–±–ª–µ–º—ã —Å JSON –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º

#### –ü—Ä–æ–±–ª–µ–º–∞: JSON parsing errors
```bash
JSONDecodeError: Expecting ',' delimiter
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö
python fix_dataset.py

# –ò—Å–ø—Ä–∞–≤—å—Ç–µ –∫–æ–¥–∏—Ä–æ–≤–∫—É
python -c "
import json
with open('data/train.jsonl', 'r', encoding='utf-8') as f:
    for i, line in enumerate(f):
        try:
            json.loads(line)
        except Exception as e:
            print(f'–û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {i+1}: {e}')
"
```

#### –ü—Ä–æ–±–ª–µ–º–∞: –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –æ—Ç–≤–µ—Ç–∞—Ö
```
–û—Ç–≤–µ—Ç: "√ê√ê√ê √¢ √ê√ê¬∞√ê¬∑√ê¬∞√ë√ë√ë√ê¬µ"
```

**–†–µ—à–µ–Ω–∏–µ:**
```python
# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ UTF-8
import sys
sys.stdout.reconfigure(encoding='utf-8')

# –ü—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏
with open('output.txt', 'w', encoding='utf-8') as f:
    f.write(response)

# –ü—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
with open('input.txt', 'r', encoding='utf-8') as f:
    text = f.read()
```

### 6. –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

#### –ü—Ä–æ–±–ª–µ–º–∞: "MPS –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω"
```bash
RuntimeError: MPS backend is not available
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–µ—Ä—Å–∏—é macOS (–Ω—É–∂–Ω–∞ 12.3+)
sw_vers

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ PyTorch
python -c "import torch; print(torch.backends.mps.is_available())"

# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ CPU –µ—Å–ª–∏ MPS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
export PYTORCH_ENABLE_MPS_FALLBACK=1
```

#### –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω—ã–π SSD
```bash
# –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–≤–æ–±–æ–¥–Ω–æ–µ –º–µ—Å—Ç–æ
df -h

# –û—á–∏—Å—Ç–∏—Ç–µ –∫—ç—à –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
rm -rf ~/.cache/huggingface/transformers/

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–∫–æ—Ä–æ—Å—Ç—å –¥–∏—Å–∫–∞
time dd if=/dev/zero of=test_file bs=1M count=1000
rm test_file
```

## üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–º–∞–Ω–¥—ã

### –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã
python check_system.py

# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–º—è—Ç–∏
python -c "
import psutil
mem = psutil.virtual_memory()
print(f'–û–±—â–∞—è RAM: {mem.total/1024**3:.1f}GB')
print(f'–î–æ—Å—Ç—É–ø–Ω–æ: {mem.available/1024**3:.1f}GB')
print(f'–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {mem.percent}%')
"

# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ MLX
python -c "
import mlx.core as mx
print(f'MLX –≤–µ—Ä—Å–∏—è: {mx.__version__}')
print(f'Unified Memory: {mx.metal.get_peak_memory()/1024**3:.1f}GB')
"
```

### –¢–µ—Å—Ç –º–æ–¥–µ–ª–∏
```python
# –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç
def quick_test():
    try:
        from mlx_lm import load, generate
        print("‚úÖ MLX –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
        
        model, tokenizer = load(
            "google/gemma-3-4b-it",
            adapter_path="./checkpoints_full"
        )
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        response = generate(
            model, tokenizer,
            prompt="<bos><start_of_turn>user\n–¢–µ—Å—Ç<end_of_turn>\n<start_of_turn>model\n",
            max_tokens=10
        )
        print(f"‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç: {response}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

quick_test()
```

## üìû –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–º–æ—â–∏

### –õ–æ–≥–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
```bash
# –í–∫–ª—é—á–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω—ã–µ –ª–æ–≥–∏
export PYTHONPATH="/path/to/project:$PYTHONPATH"
export MLX_LOG_LEVEL=DEBUG
python test_gemma_4b_full.py benchmark > debug.log 2>&1

# –û—Ç–ø—Ä–∞–≤—å—Ç–µ debug.log –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
```

### –°–±–æ—Ä –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
```python
import platform
import sys
import mlx.core as mx
from mlx_lm import __version__ as mlx_lm_version

print("=== –î–ò–ê–ì–ù–û–°–¢–ò–ß–ï–°–ö–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø ===")
print(f"OS: {platform.system()} {platform.release()}")
print(f"Python: {sys.version}")
print(f"MLX: {mx.__version__}")
print(f"MLX-LM: {mlx_lm_version}")
print(f"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {platform.machine()}")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏
import psutil
mem = psutil.virtual_memory()
print(f"RAM: {mem.total/1024**3:.1f}GB (–¥–æ—Å—Ç—É–ø–Ω–æ: {mem.available/1024**3:.1f}GB)")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
import os
if os.path.exists("checkpoints_full"):
    files = os.listdir("checkpoints_full")
    print(f"–ß–µ–∫–ø–æ–∏–Ω—Ç—ã: {files}")
else:
    print("‚ùå –ü–∞–ø–∫–∞ checkpoints_full –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
```

## üÜò –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏

### –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
```bash
# 1. –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫–∞
rm -rf ../gemma_env
python -m venv ../gemma_env
source ../gemma_env/bin/activate
pip install mlx-lm transformers datasets

# 2. –ó–∞–Ω–æ–≤–æ —Å–∫–∞—á–∞–π—Ç–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã
rm -rf checkpoints_full
python full_training.py

# 3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ M1/M2 Mac
system_profiler SPHardwareDataType | grep "Chip"
```

### –û—Ç–∫–∞—Ç –∫ —Ä–∞–±–æ—á–µ–π –≤–µ—Ä—Å–∏–∏
```bash
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–æ—Å—Ç—É—é Gemma 1B
cd ../
python test_gemma_1b.py

# –ò–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç
python -c "
from mlx_lm import load, generate
model, tokenizer = load('mlx-community/gemma-2-2b-it-4bit')
print(generate(model, tokenizer, prompt='Hello', max_tokens=5))
"
```

---

**üìû –ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ –Ω–µ —Ä–µ—à–∞–µ—Ç—Å—è:** –°–æ–∑–¥–∞–π—Ç–µ issue —Å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –∏ –ª–æ–≥–∞–º–∏. 